{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakubBrojacz/Poem-Generation/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Overview\n",
        "\n",
        "The whole thing will not produce meaningful results.\n",
        "Training time is too low with too high number of different words to teach encoder-decoder model\n",
        "We need either pretrained model or ability to run it over many hours (colab unfortunetely restarts every 2 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIvYEfOrzn7k",
        "outputId": "2702c320-53c4-4f7d-81f0-e3d00bc57549"
      },
      "outputs": [],
      "source": [
        "# 1. Add kaggle.json file with credentials to Colab\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d michaelarman/poemsdataset\n",
        "! unzip -q poemsdataset.zip\n",
        "\n",
        "# Don't look at warnings, we can skip some categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOwCv7OAXUyq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pathlib\n",
        "import unicodedata\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAKxHk5rXz8Y",
        "outputId": "f79e532a-ab00-4cbf-dc0b-bf3b0f72d333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZYzE2DfaSZ3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split()) < MAX_LENGTH and \\\n",
        "        len(p[1].split()) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-swnbhjYFNj"
      },
      "outputs": [],
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"[^a-zA-Z]+\", r\" \", s)\n",
        "    s = s.lower()\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv_cRd0LaRKT",
        "outputId": "9bf18b25-c44b-46a9-d157-e4bef2ef65a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67682\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = pathlib.Path('/content/forms')\n",
        "\n",
        "dataset = []\n",
        "for dirname in DATA_PATH.iterdir():\n",
        "  # if 'abc' not in dirname.name:\n",
        "  #     continue\n",
        "  for file_name in (DATA_PATH/dirname).iterdir():\n",
        "      line0 = ''\n",
        "      with open(file_name) as f:\n",
        "          for line in f:\n",
        "              line = normalizeString(line)\n",
        "              if line0 == '':\n",
        "                  line0=line\n",
        "                  continue\n",
        "              dataset.append([line0, line])\n",
        "              line0=''\n",
        "dataset = filterPairs(dataset)\n",
        "print(len(dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7w-U2z_X9Ss"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Tok:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        # self.word2index = {}\n",
        "        self.word2index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_igrxU-GUHPa"
      },
      "outputs": [],
      "source": [
        "t_tokenizer = Tok(\"idk\")\n",
        "for pair in dataset:\n",
        "  t_tokenizer.addSentence(pair[0])\n",
        "  t_tokenizer.addSentence(pair[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "gTh0nxqqYeXd",
        "outputId": "cab6215c-b2d2-4367-c873-a5e2a7144cef"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuxATFxgZWPr"
      },
      "outputs": [],
      "source": [
        "glove = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
        "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
        "\n",
        "word_index = t_tokenizer.word2index\n",
        "dimension = 100\n",
        "\n",
        "embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
        "for word,index in word_index.items():\n",
        "    if word in glove_embedding:\n",
        "      embedding_matrix[index]=glove_embedding[word]\n",
        "    else:\n",
        "      embedding_matrix[index]=np.random.normal(scale=0.6, size=(dimension, ))\n",
        "\n",
        "vocab_size=embedding_matrix.shape[0]\n",
        "vector_size=embedding_matrix.shape[1]\n",
        "\n",
        "embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)\n",
        "embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
        "embedding.weight.requires_grad=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzl4E7nPbg3H",
        "outputId": "773c7660-5eae-4452-889e-3301bce11205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.1851,  0.6478, -0.2503,  0.0403, -0.8263, -0.0807, -0.2397,  0.0954,\n",
              "          1.1615,  0.5814, -0.0958, -0.2305,  0.1866, -1.1271, -0.4197,  0.2191,\n",
              "         -0.3206,  0.6916, -1.0723, -1.3543,  0.6048, -0.4980,  0.0220, -1.1853,\n",
              "          0.8162,  1.0848, -0.5538, -0.1479,  1.2835,  0.0263,  0.2002,  0.8616,\n",
              "          0.0659, -1.0409,  0.7651, -0.2987,  0.5579,  0.6750, -0.1126, -0.2971,\n",
              "         -0.2820, -0.6926, -0.0708,  0.5087, -0.0880, -0.0171,  0.5061,  0.7111,\n",
              "          1.2538,  0.6433,  0.5380, -0.0028,  0.4764, -0.2339,  0.0292,  0.3930,\n",
              "         -0.7014,  0.2457, -0.1706, -0.3737,  0.7465, -0.6025,  0.1188, -1.4595,\n",
              "          0.5880, -0.1503,  1.0832,  0.9282, -0.5269, -0.9553,  0.4756, -0.9422,\n",
              "         -0.3861, -0.8488, -0.3732, -1.1486, -0.0185, -0.2662,  0.4863,  0.0359,\n",
              "          0.9313, -0.1165, -0.3677,  0.5302, -0.4028, -0.3753,  0.9071,  1.2371,\n",
              "         -0.2545, -0.1301, -0.5088,  0.2781, -0.7636, -0.8144,  0.4945,  0.5035,\n",
              "         -1.2912,  0.5619,  0.8860, -0.4399]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding(torch.LongTensor([1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mzU0mKvQ_Qd",
        "outputId": "d5377c97-ffb0-46ce-f4dc-386da83c9f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0m 25s (- 3m 45s) (1000 10%) 5.9477\n",
            "0m 52s (- 3m 28s) (2000 20%) 6.0431\n",
            "1m 19s (- 3m 4s) (3000 30%) 6.0212\n",
            "1m 47s (- 2m 41s) (4000 40%) 5.8996\n",
            "2m 13s (- 2m 13s) (5000 50%) 5.8143\n",
            "2m 41s (- 1m 47s) (6000 60%) 5.9186\n",
            "3m 8s (- 1m 20s) (7000 70%) 5.9219\n",
            "3m 35s (- 0m 53s) (8000 80%) 5.7473\n",
            "4m 2s (- 0m 26s) (9000 90%) 5.7862\n",
            "4m 30s (- 0m 0s) (10000 100%) 5.8326\n",
            "> the flowers have had a frost \n",
            "= each herb hath lost her savour \n",
            "< i the EOS\n",
            "\n",
            "> doth straight forget the dangers of the sea \n",
            "= but i vnhappie i can neuer show \n",
            "< i the the EOS\n",
            "\n",
            "> equal trophies of thine art \n",
            "= e en the flowing azure air\n",
            "< i the EOS\n",
            "\n",
            "> elegance\n",
            "= ene rgetic\n",
            "< EOS\n",
            "\n",
            "> than the day visions of a mind unsound \n",
            "= disorder d phantasies indulged too much \n",
            "< i the the EOS\n",
            "\n",
            "> ye tender objects of maternal love \n",
            "= ye dearest joys my widow d heart can prove \n",
            "< i the EOS\n",
            "\n",
            "> poetasters are anonymous in every town\n",
            "= and they never do know of literary renown \n",
            "< i the EOS\n",
            "\n",
            "> thus partridge by his wit and parts\n",
            "= at once did practise both these arts \n",
            "< i the the EOS\n",
            "\n",
            "> epic journey\n",
            "= this story happened before the invention of snow scooters \n",
            "< EOS\n",
            "\n",
            "> i got it all happening god s grace \n",
            "=  cause we would never like our dreams to fail \n",
            "< i the the EOS\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Based on \n",
        "# https://github.com/pytorch/tutorials/blob/master/intermediate_source/seq2seq_translation_tutorial.py\n",
        "# with our changes\n",
        "\n",
        "pairs=dataset\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)\n",
        "        self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad=False\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)\n",
        "        self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad=False\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)\n",
        "        self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad=False\n",
        "\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "  res = []\n",
        "  try:\n",
        "    res = [lang.word2index[word] for word in sentence.split()]\n",
        "  except Exception as e:\n",
        "    print(sentence)\n",
        "    raise\n",
        "  return res\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    res = torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "    # print(sentence)\n",
        "    # print(res)\n",
        "    # input()\n",
        "    return res\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(t_tokenizer, pair[0])\n",
        "    target_tensor = tensorFromSentence(t_tokenizer, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "def train_no_attention(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "# TODO change this to tqdm\n",
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# The whole training process looks like this:\n",
        "#\n",
        "# -  Start a timer\n",
        "# -  Initialize optimizers and criterion\n",
        "# -  Create set of training pairs\n",
        "# -  Start empty losses array for plotting\n",
        "#\n",
        "# Then we call ``train`` many times and occasionally print the progress (%\n",
        "# of examples, time so far, estimated time) and average loss.\n",
        "#\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, use_attention, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        if use_attention:\n",
        "          loss = train(input_tensor, target_tensor, encoder,\n",
        "                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        else:\n",
        "          loss = train_no_attention(input_tensor, target_tensor, encoder,\n",
        "                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Plotting results\n",
        "# ----------------\n",
        "#\n",
        "# Plotting is done with matplotlib, using the array of loss values\n",
        "# ``plot_losses`` saved while training.\n",
        "#\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Evaluation\n",
        "# ==========\n",
        "#\n",
        "# Evaluation is mostly the same as training, but there are no targets so\n",
        "# we simply feed the decoder's predictions back to itself for each step.\n",
        "# Every time it predicts a word we add it to the output string, and if it\n",
        "# predicts the EOS token we stop there. We also store the decoder's\n",
        "# attention outputs for display later.\n",
        "#\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(t_tokenizer, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('EOS')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(t_tokenizer.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "\n",
        "def evaluate_no_attention(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(t_tokenizer, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('EOS')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(t_tokenizer.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# We can evaluate random sentences from the training set and print out the\n",
        "# input, target, and output to make some subjective quality judgements:\n",
        "#\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, use_attention, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        if use_attention:\n",
        "          output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        else:\n",
        "          output_words = evaluate_no_attention(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Training and Evaluating\n",
        "# =======================\n",
        "#\n",
        "# With all these helper functions in place (it looks like extra work, but\n",
        "# it makes it easier to run multiple experiments) we can actually\n",
        "# initialize a network and start training.\n",
        "#\n",
        "# Remember that the input sentences were heavily filtered. For this small\n",
        "# dataset we can use relatively small networks of 256 hidden nodes and a\n",
        "# single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
        "# reasonable results.\n",
        "#\n",
        "# .. Note::\n",
        "#    If you run this notebook you can train, interrupt the kernel,\n",
        "#    evaluate, and continue training later. Comment out the lines where the\n",
        "#    encoder and decoder are initialized and run ``trainIters`` again.\n",
        "#\n",
        "\n",
        "use_attention=True\n",
        "hidden_size = vector_size\n",
        "encoder1 = EncoderRNN(t_tokenizer.n_words, hidden_size).to(device)\n",
        "if use_attention:\n",
        "  attn_decoder1 = AttnDecoderRNN(hidden_size, t_tokenizer.n_words, dropout_p=0.1).to(device)\n",
        "else:\n",
        "  attn_decoder1 = DecoderRNN(hidden_size, t_tokenizer.n_words).to(device)\n",
        "# use_attention=True\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 10000, print_every=1000, use_attention=use_attention)\n",
        "\n",
        "######################################################################\n",
        "#\n",
        "\n",
        "evaluateRandomly(encoder1, attn_decoder1, use_attention=use_attention)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "6i2m75kyS-rQ",
        "outputId": "acc961b6-98a9-44ac-a781-d2eda2bcc12d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# After maaany trainIters we can sometimes get more than 5 different words. We need pretrained model.... \n",
        "# Or at least place where we can run it over the night \n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=1000, use_attention=use_attention)\n",
        "\n",
        "######################################################################\n",
        "#\n",
        "\n",
        "# evaluateRandomly(encoder1, attn_decoder1, use_attention=use_attention)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Kopia notatnika main.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f2575392019334285e0602a4035eec46b9260ee4c95297ea34ade6e3c8b8fcaf"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
